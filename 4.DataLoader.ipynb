{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader(dataset, batchsize, num_works(num of thread), shuffle)\n",
    "#  __init__(self, parameter)\n",
    "# __getitem__(self, index) return data of index\n",
    "# __len(self)__ return len of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader,Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./resource/captcha/\n"
     ]
    }
   ],
   "source": [
    "folder = './resource/captcha/'\n",
    "print(folder) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0Bh6_4332.jpg', '0bZ7_4589.jpg', '0BzA_1968.jpg', '0ChZ_150.jpg', '0dYm_2012.jpg', '0Edn_641.jpg', '0ETf_2099.jpg', '0Fpk_1265.jpg', '0G4Q_4661.jpg', '0gXk_2418.jpg', '0HHk_1191.jpg', '0Hv3_3687.jpg', '0icS_947.jpg', '0j6d_2153.jpg', '0j6h_190.jpg', '0jCf_649.jpg', '0JH0_4333.jpg', '0jNh_3144.jpg', '0JSg_4544.jpg', '0KHj_719.jpg', '0l5T_4133.jpg', '0LIg_812.jpg', '0Mmq_1084.jpg', '0mOu_2350.jpg', '0ni3_1286.jpg', '0NyG_445.jpg', '0OXQ_3443.jpg', '0pFy_2659.jpg', '0pn5_4182.jpg', '0Q6n_2196.jpg', '0QWZ_1802.jpg', '0qYn_1628.jpg', '0rBn_1467.jpg', '0rwJ_3930.jpg', '0s4h_2235.jpg', '0sqT_2590.jpg', '0TXO_3748.jpg', '0uGz_3426.jpg', '0vJc_2448.jpg', '0VPH_3155.jpg', '0VsB_416.jpg', '0wqv_1171.jpg', '0Wtp_2016.jpg', '0xEW_3224.jpg', '0xIR_4009.jpg', '0XYT_1077.jpg', '0Xzn_3518.jpg', '0yAM_4454.jpg', '0yg5_471.jpg']\n"
     ]
    }
   ],
   "source": [
    "captcha_list = os.listdir(folder)\n",
    "print(captcha_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mydataset(Dataset):\n",
    "\n",
    "    def __init__(self, root_dir, transform=None):  # transform for image\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.images = os.listdir(self.root_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_index = self.images[index]  # choose image\n",
    "        img_path = os.path.join(self.root_dir, image_index) \n",
    "        image_name = img_path.split('/')[-1]\n",
    "        image = Image.open(img_path)\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, image_name.split('.')[0]\n",
    "\n",
    "    \n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize([224, 224]),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307, 0.1307, 0.1307), (0.3081, 0.3081, 0.3081))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Mydataset(folder, transform)\n",
    "dl = DataLoader(ds, batch_size=7, shuffle=True)\n",
    "# 7 * 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show image\n",
    "def tensor_to_PIL(tensor):\n",
    "    unloader = transforms.ToPILImage()\n",
    "    image = tensor.cpu().clone()\n",
    "    image = image.squeeze(0)\n",
    "    image = unloader(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('0xIR_4009', '0Hv3_3687', '0vJc_2448', '0uGz_3426', '0NyG_445', '0ni3_1286', '0Mmq_1084')\n",
      "('0QWZ_1802', '0jNh_3144', '0dYm_2012', '0icS_947', '0gXk_2418', '0Xzn_3518', '0qYn_1628')\n",
      "('0Fpk_1265', '0pFy_2659', '0OXQ_3443', '0yg5_471', '0l5T_4133', '0JH0_4333', '0XYT_1077')\n",
      "('0yAM_4454', '0jCf_649', '0VsB_416', '0xEW_3224', '0LIg_812', '0wqv_1171', '0rwJ_3930')\n",
      "('0j6h_190', '0G4Q_4661', '0s4h_2235', '0Bh6_4332', '0Edn_641', '0bZ7_4589', '0Wtp_2016')\n",
      "('0KHj_719', '0JSg_4544', '0VPH_3155', '0TXO_3748', '0HHk_1191', '0sqT_2590', '0j6d_2153')\n",
      "('0Q6n_2196', '0BzA_1968', '0ChZ_150', '0rBn_1467', '0pn5_4182', '0mOu_2350', '0ETf_2099')\n"
     ]
    }
   ],
   "source": [
    "for i, inp in enumerate(dl):\n",
    "    image, name = inp\n",
    "    print(name)\n",
    "    if i==0:\n",
    "        image = tensor_to_PIL(image[0])\n",
    "        image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
